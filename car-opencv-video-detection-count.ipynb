{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|                       |Total number of cars |Cars per minute|\n",
    "|-----------------------|---------------------|--------------|\n",
    "| Traffic_Laramie_1.mp4 | 6 | 2.02|\n",
    "| Traffic_Laramie_2.mp4 | 4 | 2.27|\n",
    "\n",
    "# Brief description of the frame differencing and background subtraction techniques\n",
    "Both the frame differencing and background subtraction techniques are used in video processing for the purpose of\n",
    "movement detection. They compare pixels of 2 frames and calculate the difference between them. The regions with\n",
    "significant differences (above some threshold) are considered regions with some motion.\n",
    "While background subtraction uses some relatively persistent image as a background and each other frame of the\n",
    "video as an image to compare with the background, the frame differencing compares each consecutive pair of\n",
    "frames in the video.\n",
    "Both techniques require preprocessing the frames to simplify the calculation of the difference between pixels and\n",
    "focus more on the movement itself than the exact borders of the moving objects. Usually, that preprocessing includes\n",
    "grayscaling an image and applying a Gaussian Blur filter. But it also may include other approaches, for example,\n",
    "image dilation to minimize small inaccuracies.\n",
    "For background subtraction, it is a key task to choose a proper background and change it accordingly depending on\n",
    "the light conditions and other environment changes. The frame differencing does not require that, but it can be less\n",
    "accurate in detecting slowly moving objects.\n",
    "# Brief analysis of the application\n",
    "OpenCV library is used as the main tool for the implementation of the required functionality. I define helper functions\n",
    "to calculate and draw the Main Street border coordinates. Also, I extracted a function for preprocessing a frame.\n",
    "The main logic starts with reading a video file, the initial (background) frame, and its preprocessing. Then, in the\n",
    "loop, it reads each next frame until no frames are left. The assessment says that the application must be based on\n",
    "the frame differencing and background subtraction techniques. It is unclear if it is allowed to use only one of them.\n",
    "Hence, my application uses both those techniques. For each iteration, I calculate 2 deltas: the first is between the\n",
    "current frame and the background, and the second is between the current and previous frames. Each of those deltas\n",
    "contributes to the resulting delta with 0.5 of weight. After calculating a threshold on the delta frame, I use\n",
    "findContours from the OpenCV library to detect object boundaries. Objects with a total area of less than 3000 are\n",
    "ignored. The found objects are framed into green rectangles.\n",
    "The car’s counter is implemented by counting cars that cross a manually selected barrier. For that purpose, I check if\n",
    "the top left angle of any of the detected rectangles is located on the left from and, at the same time, close to the\n",
    "barrier. To avoid duplicates, I count such events only if there was a rectangle on the right from the barrier before.\n",
    "That is not the most beautiful solution, but it works pretty well."
   ],
   "id": "44701fd39a39e1c7"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "Start with installing required dependencies.",
   "id": "893bcb4ad762ffcc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/bastrich/isp-final/lib/python3.11/site-packages (1.26.3)\r\n",
      "Requirement already satisfied: opencv-python in /Users/bastrich/isp-final/lib/python3.11/site-packages (4.9.0.80)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:37.362903Z",
     "start_time": "2024-01-30T19:28:35.244398Z"
    }
   },
   "id": "13592125d0c0ff1c",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import required dependencies."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add3f7d215828dd1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:38.903732Z",
     "start_time": "2024-01-30T19:28:38.712975Z"
    }
   },
   "id": "47958ef5438f90d3",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a method to draw a red rectangle in open cv frame as shown in the screenshot from assessment."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9636ff6199251f5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def draw_dashed_rectangle(frame, start_point, end_point, color = (0, 0, 255), thickness = 4, dash_length = 15):\n",
    "    start_x, start_y = start_point\n",
    "    end_x, end_y = end_point\n",
    "\n",
    "    for x in range(start_x, end_x, dash_length * 2):\n",
    "        start_point = (x, start_y)\n",
    "        end_point = (min(x + dash_length, end_x), start_y)\n",
    "        cv2.line(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "        start_point = (x, end_y)\n",
    "        end_point = (min(x + dash_length, end_x), end_y)\n",
    "        cv2.line(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "    for y in range(start_y, end_y, dash_length * 2):\n",
    "        start_point = (start_x, y)\n",
    "        end_point = (start_x, min(y + dash_length, end_y))\n",
    "        cv2.line(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "        start_point = (end_x, y)\n",
    "        end_point = (end_x, min(y + dash_length, end_y))\n",
    "        cv2.line(frame, start_point, end_point, color, thickness)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:40.400096Z",
     "start_time": "2024-01-30T19:28:40.393584Z"
    }
   },
   "id": "7cb479c165e649dd",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a method returning coordinates of the Main Street borders."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7196878d69df8c7a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_main_street_border_coordinates(frame):\n",
    "    return (\n",
    "        2,\n",
    "        int(frame.shape[0] * 0.43),\n",
    "        frame.shape[1] - 4,\n",
    "        frame.shape[0] - 10\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:41.831200Z",
     "start_time": "2024-01-30T19:28:41.826818Z"
    }
   },
   "id": "efb57ca0d3a5b85e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a method for a frame preprocessing. We crop the main street, apply grayscale and Gaussian Blur effects. Such a preprocessing simplifies car detection algorithm and improves its performance allowing to avoid unnecessary image details."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecbc8096a5c2ebf3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, main_street_start_x, main_street_start_y, main_street_end_x, main_street_end_y):\n",
    "    detection_frame = frame[main_street_start_y:main_street_end_y, main_street_start_x:main_street_end_x]\n",
    "    gray_frame = cv2.cvtColor(detection_frame, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.GaussianBlur(gray_frame, (25,25), 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:43.351847Z",
     "start_time": "2024-01-30T19:28:43.348540Z"
    }
   },
   "id": "221f257e2bece1dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a method to count cars given a vide file path."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9d5c8bf87f98d33"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def count_cars(video_file_path):\n",
    "\n",
    "    # read video file\n",
    "    video=cv2.VideoCapture(video_file_path)\n",
    "    \n",
    "    # find the video duration in minutes\n",
    "    duration = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) / video.get(cv2.CAP_PROP_FPS) / 60\n",
    "\n",
    "    # read initial frame without cars for using in background subtraction\n",
    "    initial_frame = video.read()[1]\n",
    "\n",
    "    # define main street borders\n",
    "    main_street_start_x, main_street_start_y, main_street_end_x, main_street_end_y = get_main_street_border_coordinates(initial_frame)\n",
    "\n",
    "    # preprocess initial frame\n",
    "    initial_frame = preprocess_frame(initial_frame, main_street_start_x, main_street_start_y, main_street_end_x, main_street_end_y)\n",
    "\n",
    "    # prepare previous frame for using in frame differencing \n",
    "    prev_frame = initial_frame\n",
    "\n",
    "    # read the next frame\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    # define a barrier line coordinates\n",
    "    # crossing this line is counted as moving from the city’s downtown to the city centre\n",
    "    count_barrier_start_x = main_street_start_x + 600\n",
    "    count_barrier_start_y = main_street_start_y + 100\n",
    "    count_barrier_end_x = count_barrier_start_x\n",
    "    count_barrier_end_y = main_street_start_y + 170\n",
    "\n",
    "    # init a flag to not count already counted car\n",
    "    prev_car_before_barrier = False\n",
    "\n",
    "    # init the current count to 0\n",
    "    count = 0\n",
    "\n",
    "    while check:\n",
    "\n",
    "        # preprocess the current frame\n",
    "        blur_frame = preprocess_frame(frame, main_street_start_x, main_street_start_y, main_street_end_x, main_street_end_y)\n",
    "\n",
    "        # calculate \"delta\" frame using frame differencing and background subtraction techniques at the same time\n",
    "        delta_frame = (cv2.absdiff(initial_frame, blur_frame) * 0.5 + cv2.absdiff(prev_frame, blur_frame) * 0.5).astype(np.uint8)\n",
    "\n",
    "        # apply threshold to the \"delta\" frame for ease of objects detection\n",
    "        threshold_frame=cv2.threshold(delta_frame, 12, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # find objects contours in the threshold frame\n",
    "        contours, _ = cv2.findContours(threshold_frame,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # iterate over found objects\n",
    "        for c in contours:\n",
    "\n",
    "            # skip small objects (people, bicycles, etc.)\n",
    "            if cv2.contourArea(c) < 3000:\n",
    "                continue\n",
    "\n",
    "            # find coordinates of a rectangle around the object\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "            # draw rectangle as shown in the screenshot from assessment\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (x + main_street_start_x, y + main_street_start_y),\n",
    "                (x+ main_street_start_x + w, y+main_street_start_y+h),\n",
    "                (0,255,0),\n",
    "                1\n",
    "            )\n",
    "            \n",
    "            # count cars\n",
    "            # if the car just crossed the line and there was a detected car before the line (basically the same car)\n",
    "            if count_barrier_end_x - 50 < main_street_start_x + x  < count_barrier_start_x \\\n",
    "                and y + main_street_start_y < count_barrier_end_y \\\n",
    "                and prev_car_before_barrier:\n",
    "                    # increment counter\n",
    "                    count += 1\n",
    "                    # set flag for car detected before the line to False\n",
    "                    prev_car_before_barrier = False\n",
    "            # if there is a car right before the line\n",
    "            if count_barrier_start_x < main_street_start_x + x < count_barrier_end_x + 50 and y + main_street_start_y < count_barrier_end_y:\n",
    "                # set flag for car detected before the line to True\n",
    "                prev_car_before_barrier = True\n",
    "\n",
    "        # draw the barrier line for better visual understanding\n",
    "        cv2.line(frame, (count_barrier_start_x, count_barrier_start_y), (count_barrier_end_x, count_barrier_end_y), (255, 0, 0), 4)\n",
    "\n",
    "        # draw the street text label as shown in the screenshot from assessment\n",
    "        cv2.putText(frame, 'Main street', (main_street_start_x, main_street_start_y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,255), 3)\n",
    "\n",
    "        # draw counter\n",
    "        cv2.putText(frame, str(count), (main_street_end_x - 60, main_street_start_y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,255), 3)\n",
    "\n",
    "        # draw Main Street borders as shown in the screenshot from assessment\n",
    "        draw_dashed_rectangle(\n",
    "            frame = frame,\n",
    "            start_point = (main_street_start_x, main_street_start_y),\n",
    "            end_point = (main_street_end_x, main_street_end_y)\n",
    "        )\n",
    "\n",
    "        # show detected cars and counter\n",
    "        cv2.imshow('Traffic Camera', frame)\n",
    "\n",
    "        # update the previous frame\n",
    "        prev_frame = blur_frame\n",
    "\n",
    "        # read the next frame\n",
    "        check, frame = video.read()\n",
    "\n",
    "        # handle quit\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # gracefully shutdown the demonstration\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # return the count and the cars rate per minute\n",
    "    return count, round(count / duration, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:28:45.050152Z",
     "start_time": "2024-01-30T19:28:45.040622Z"
    }
   },
   "id": "48a609af8c1ad8a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterate over the video files, count cars and print the result."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a892ccdb4f462fb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: Traffic_Laramie_2.mp4, Total number of cars: 4, Cars per minute: 2.27\n",
      "File Name: Traffic_Laramie_1.mp4, Total number of cars: 6, Cars per minute: 2.02\n"
     ]
    }
   ],
   "source": [
    "for video_file in [file for file in os.listdir('Exercise1_Files') if file.endswith('.mp4')]:\n",
    "    total_number_of_cars, cars_per_minute = count_cars(f'Exercise1_Files/{video_file}')\n",
    "    print(f'File Name: {video_file}, Total number of cars: {total_number_of_cars}, Cars per minute: {cars_per_minute}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T19:31:20.726729Z",
     "start_time": "2024-01-30T19:28:46.794400Z"
    }
   },
   "id": "bcfc1a1a678870dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
